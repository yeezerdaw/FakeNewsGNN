
# Fake News Detection with Graph Neural Networks (GNN)  

A machine learning model that classifies fake news using **GraphSAGE** and **BERT embeddings**, analyzing social network propagation patterns.

---

## Features  
âœ… **GraphSAGE-based GNN** for learning from news propagation networks.  
âœ… **BERT embeddings** for text representation (static embeddings).  
âœ… **Multi-class classification** with six truthfulness categories.  
âœ… **End-to-end pipeline** including dataset loading, feature extraction, training, and evaluation.  

---

## ğŸ“‚ Project Structure  
```
FakeNewsGNN/
â”‚â”€â”€ dataset.py              # Loads and preprocesses the LIAR dataset
â”‚â”€â”€ feature_extraction.py   # Extracts static BERT embeddings
â”‚â”€â”€ graph.py                # Constructs the graph representation
â”‚â”€â”€ model.py                # Defines the GraphSAGE-based model
â”‚â”€â”€ train.py                # Handles training and evaluation
â”‚â”€â”€ main.py                 # Main script to run the pipeline
â”‚â”€â”€ requirements.txt        # Dependencies for installation
â”‚â”€â”€ README.md               # Project documentation
```

---

## Dataset  
The model is trained on the **LIAR Dataset**, sourced from [Hugging Face](https://huggingface.co/datasets/liar). It consists of **12,800 manually labeled short news statements**, categorized into six levels of truthfulness:  

- âŒ **False**  
- ğŸ”¥ **Pants-fire (extremely false)**  
- ğŸŸ¡ **Barely-true**  
- ğŸŸ¡ **Half-true**  
- ğŸŸ¢ **Mostly-true**  
- âœ… **True**  

---

## Installation & Usage  

###  1. Clone the Repository  
```bash
git clone https://github.com/yourusername/FakeNewsGNN.git
cd FakeNewsGNN
```

###  2. Install Dependencies  
```bash
pip install -r requirements.txt
```

###  3. Run the Model  
```bash
python main.py
```

---

## ğŸ¯ Results  
**Training for 1000 epochs** with a **learning rate scheduler** achieved:  
**87.02% accuracy on the LIAR dataset!**  

## Latest Update: Achieved **90% Accuracy**
### Optimizations:
âœ” Enabled **FP16 (Mixed Precision)** to **reduce GPU memory usage**  
âœ” **Batch size adjusted** dynamically to **avoid CUDA OOM**  
âœ” **CUDA Memory Management Tweaks** improved **speed & stability**  

### ğŸ“Œ Further improvements:  
- **Fine-tuning BERT** instead of using static embeddings.  
- **Experimenting with GAT (Graph Attention Networks)** for better learning.  
- **Adding data augmentation** for more diverse training samples.  

---

## Model Architecture  
The model follows this pipeline:  

```plaintext
[News Text] â†’ [BERT Embeddings (768-D)] â†’ [GraphSAGE Layers] â†’ [Fully Connected Layer] â†’ [Classification]
```

---

## ğŸ¤ Contributing  
Contributions are welcome! Feel free to **fork**, **open issues**, or **submit PRs** to improve the project.  

---

## ğŸ“ License  
This project is open-source and available under the **MIT License**.  
```
